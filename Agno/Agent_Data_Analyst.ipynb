{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUw0TJmGvyrHFLcROojS8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royn5618/AgenticExperiments/blob/main/Agno/Agent_Data_Analyst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Test an agent who can analyse and answer questions on an input CSV.\n",
        "\n",
        "Not Completed - Producing Errors"
      ],
      "metadata": {
        "id": "sljid-xqwNOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "KPukqdQ0piwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sqlalchemy 'psycopg[binary]' pgvector\n",
        "!pip install agno"
      ],
      "metadata": {
        "id": "Z6kj7EF-pd_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Keys Set-Up"
      ],
      "metadata": {
        "id": "3MzTVntwr-jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "t4qu11B9r-Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-Up Vector Database"
      ],
      "metadata": {
        "id": "sCioMzeNsBeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def udocker_init():\n",
        "    if not os.path.exists(\"/home/user\"):\n",
        "        !pip install udocker > /dev/null\n",
        "        !udocker --allow-root install > /dev/null\n",
        "        !useradd -m user > /dev/null\n",
        "    print(f'Docker-in-Colab 1.1.0\\n')\n",
        "    print(f'Usage:     udocker(\"--help\")')\n",
        "    print(f'Examples:  https://github.com/indigo-dc/udocker?tab=readme-ov-file#examples')\n",
        "\n",
        "    def execute(command: str):\n",
        "        user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
        "        print(f\"{user_prompt}$ udocker {command}\")\n",
        "        !su - user -c \"udocker $command\"\n",
        "\n",
        "    return execute\n",
        "\n",
        "udocker = udocker_init()\n",
        "\n",
        "# Set-Up PgVector Database\n",
        "\n",
        "# 1. Install udocker\n",
        "!udocker --allow-root install\n",
        "\n",
        "# 2. Kill existing processes and clean up\n",
        "!pkill -9 -f postgres\n",
        "!rm -rf /content/pgdata\n",
        "!udocker --allow-root rm pgvector\n",
        "!rm -f postgres.log\n",
        "\n",
        "# 3. Create fresh directory\n",
        "!mkdir -p /content/pgdata\n",
        "!chmod -R 777 /content/pgdata\n",
        "\n",
        "# 4. Pull and create container with correct image path\n",
        "!udocker --allow-root pull ankane/pgvector\n",
        "!udocker --allow-root create --name=pgvector ankane/pgvector\n",
        "\n",
        "# 5. Run the container\n",
        "!nohup udocker --allow-root run \\\n",
        "    --env=\"POSTGRES_DB=ai\" \\\n",
        "    --env=\"POSTGRES_USER=ai\" \\\n",
        "    --env=\"POSTGRES_PASSWORD=ai\" \\\n",
        "    --env=\"PGDATA=/var/lib/postgresql/data/pgdata\" \\\n",
        "    --volume=\"/content/pgdata:/var/lib/postgresql/data\" \\\n",
        "    --publish=\"5532:5432\" \\\n",
        "    pgvector > postgres.log 2>&1 &\n",
        "\n",
        "# 6. Connection testing\n",
        "import time\n",
        "from sqlalchemy import create_engine, text\n",
        "from sqlalchemy.exc import OperationalError\n",
        "\n",
        "def test_db_connection(max_retries=5, wait_time=10):\n",
        "    db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"\\nConnection attempt {attempt + 1}/{max_retries}\")\n",
        "            engine = create_engine(db_url)\n",
        "            with engine.connect() as connection:\n",
        "                result = connection.execute(text(\"SELECT version();\"))\n",
        "                version = result.fetchone()[0]\n",
        "                print(\"✅ Successfully connected to PostgreSQL!\")\n",
        "                print(f\"Server Version: {version}\")\n",
        "\n",
        "                # Test vector extension\n",
        "                connection.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector;\"))\n",
        "                print(\"✅ Vector extension ready!\")\n",
        "                return engine\n",
        "        except OperationalError as e:\n",
        "            print(f\"Attempt {attempt + 1} failed, waiting {wait_time} seconds...\")\n",
        "            print(\"\\nChecking postgres status:\")\n",
        "            !ps aux | grep postgres\n",
        "            print(\"\\nLatest logs:\")\n",
        "            !tail -n 20 postgres.log\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "    return None\n",
        "\n",
        "# 7. Apply 30 secs sleep time to wait for DB to finish set up before testing for connection\n",
        "print(\"Waiting for database to initialize...\")\n",
        "time.sleep(30)\n",
        "\n",
        "engine = test_db_connection()\n",
        "\n",
        "if engine:\n",
        "    print(\"\\n✅ Database is ready for RAG Agent initialization!\")\n",
        "else:\n",
        "    print(\"\\n❌ Database connection failed. Please check the logs above.\")"
      ],
      "metadata": {
        "id": "_dtYOU1Mp-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analyst Agent"
      ],
      "metadata": {
        "id": "_YSDNayQpe-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agno.agent import Agent\n",
        "from agno.knowledge.csv import CSVKnowledgeBase\n",
        "from agno.vectordb.pgvector import PgVector\n",
        "from agno.models.openai import\n",
        "from agno.embedder.google import GeminiEmbedder\n",
        "\n",
        "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
        "\n",
        "knowledge_base = CSVKnowledgeBase(\n",
        "    path=\"Data/airlines_flights_data.csv\",\n",
        "    vector_db=PgVector(\n",
        "        table_name=\"csv_documents\",\n",
        "        db_url=db_url,\n",
        "        embedder=GeminiEmbedder(),\n",
        "    ),\n",
        "    num_documents=5,  # Number of documents to return on search\n",
        ")\n"
      ],
      "metadata": {
        "id": "BSL-60aPqbJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the knowledge base\n",
        "knowledge_base.load(recreate=False)"
      ],
      "metadata": {
        "id": "gSTGuh1nsuZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Agent with the knowledge_base\n",
        "agent = Agent(\n",
        "    model=Gemini(\"gemini-1.5-flash\"),\n",
        "    knowledge=knowledge_base,\n",
        "    search_knowledge=True,\n",
        ")"
      ],
      "metadata": {
        "id": "iKC8Pj4ysuVp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}